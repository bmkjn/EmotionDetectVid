{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the required libraries","metadata":{}},{"cell_type":"code","source":"# c\nimport matplotlib.pyplot as plt\nfrom glob import glob # to create a list of all the files present in a directory\nimport cv2\nimport random # to choose anything in random\nimport os\n%matplotlib inline\n\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D\n# convo2d is used to read images and learn features from them.\nfrom tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\nfrom IPython.display import SVG, Image\nimport tensorflow as tf \nprint(\"tensorflow version: \",tf.__version__)","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:19:20.848609Z","iopub.status.busy":"2024-02-26T12:19:20.848214Z","iopub.status.idle":"2024-02-26T12:19:34.116867Z","shell.execute_reply":"2024-02-26T12:19:34.115721Z","shell.execute_reply.started":"2024-02-26T12:19:20.848578Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","output_type":"stream","text":"2024-03-07 15:53:31.473918: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"},{"name":"stdout","output_type":"stream","text":"tensorflow version:  2.12.0\n"}]},{"cell_type":"markdown","source":"## Preparing training and test data","metadata":{}},{"cell_type":"code","source":"img_size = 48\nbatch_size = 64\ndatagen_train = ImageDataGenerator(horizontal_flip=True)\ntrain_gen = datagen_train.flow_from_directory(\"/kaggle/input/fer2013/train/\",target_size = (img_size,img_size),color_mode=\"grayscale\",batch_size=batch_size,class_mode=\"categorical\",shuffle=True)\n\ndatagen_validation = ImageDataGenerator(horizontal_flip=True)\ntrain_validation = datagen_train.flow_from_directory(\"/kaggle/input/fer2013/test/\",target_size = (img_size,img_size),color_mode=\"grayscale\",batch_size=batch_size,class_mode=\"categorical\",shuffle=True)\n","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:20:37.334766Z","iopub.status.busy":"2024-02-26T12:20:37.334408Z","iopub.status.idle":"2024-02-26T12:20:49.236509Z","shell.execute_reply":"2024-02-26T12:20:49.235483Z","shell.execute_reply.started":"2024-02-26T12:20:37.334740Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"Found 28709 images belonging to 7 classes.\n\nFound 7178 images belonging to 7 classes.\n"}]},{"cell_type":"markdown","source":"## Building Model layers","metadata":{}},{"cell_type":"code","source":"def Convolution(input_tensor, filters, kernel_size):\n    x = Conv2D(filters=filters,kernel_size=kernel_size,padding=\"same\")(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = Dropout(0.25)(x)\n\n    return x","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:21:14.750983Z","iopub.status.busy":"2024-02-26T12:21:14.750609Z","iopub.status.idle":"2024-02-26T12:21:14.756789Z","shell.execute_reply":"2024-02-26T12:21:14.755767Z","shell.execute_reply.started":"2024-02-26T12:21:14.750955Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def Dense_f(input_tensor, nodes):\n    x = Dense(nodes)(input_tensor)\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    x = Dropout(0.25)(x)\n\n    return x","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:21:15.732768Z","iopub.status.busy":"2024-02-26T12:21:15.732149Z","iopub.status.idle":"2024-02-26T12:21:15.737927Z","shell.execute_reply":"2024-02-26T12:21:15.736788Z","shell.execute_reply.started":"2024-02-26T12:21:15.732740Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def model_fer(input_shape):\n    inputs = Input(input_shape)\n    conv_i = Convolution(inputs,64,(3,3))\n    conv_ii = Convolution(conv_i,128,(5,5))\n    conv_iii = Convolution(conv_ii,512,(3,3))\n    conv_iv = Convolution(conv_iii,512,(3,3))\n\n    flatten = Flatten()(conv_iv)\n\n    dense_i = Dense_f(flatten,256)\n    dense_ii = Dense_f(dense_i,512)\n    output = Dense(7,activation=\"softmax\")(dense_ii)\n    model = Model(inputs=[inputs], outputs=[output])\n    \n    opt = Adam(lr=0.0005)\n\n    model.compile(loss=['categorical_crossentropy'], optimizer=opt, metrics=['accuracy'])\n\n    return model","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:25:29.037043Z","iopub.status.busy":"2024-02-26T12:25:29.036349Z","iopub.status.idle":"2024-02-26T12:25:29.043984Z","shell.execute_reply":"2024-02-26T12:25:29.043013Z","shell.execute_reply.started":"2024-02-26T12:25:29.036997Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = model_fer((48,48,1))\nmodel.summary()","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:25:45.572887Z","iopub.status.busy":"2024-02-26T12:25:45.572063Z","iopub.status.idle":"2024-02-26T12:25:46.547910Z","shell.execute_reply":"2024-02-26T12:25:46.546246Z","shell.execute_reply.started":"2024-02-26T12:25:45.572848Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"model\"\n\n_________________________________________________________________\n\n Layer (type)                Output Shape              Param #   \n\n=================================================================\n\n input_1 (InputLayer)        [(None, 48, 48, 1)]       0         \n\n                                                                 \n\n conv2d (Conv2D)             (None, 48, 48, 64)        640       \n\n                                                                 \n\n batch_normalization (Batch  (None, 48, 48, 64)        256       \n\n Normalization)                                                  \n\n                                                                 \n\n activation (Activation)     (None, 48, 48, 64)        0         \n\n                                                                 \n\n max_pooling2d (MaxPooling2  (None, 24, 24, 64)        0         \n\n D)                                                              \n\n                                                                 \n\n dropout (Dropout)           (None, 24, 24, 64)        0         \n\n                                                                 \n\n conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n\n                                                                 \n\n batch_normalization_1 (Bat  (None, 24, 24, 128)       512       \n\n chNormalization)                                                \n\n                                                                 \n\n activation_1 (Activation)   (None, 24, 24, 128)       0         \n\n                                                                 \n\n max_pooling2d_1 (MaxPoolin  (None, 12, 12, 128)       0         \n\n g2D)                                                            \n\n                                                                 \n\n dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n\n                                                                 \n\n conv2d_2 (Conv2D)           (None, 12, 12, 512)       590336    \n\n                                                                 \n\n batch_normalization_2 (Bat  (None, 12, 12, 512)       2048      \n\n chNormalization)                                                \n\n                                                                 \n\n activation_2 (Activation)   (None, 12, 12, 512)       0         \n\n                                                                 \n\n max_pooling2d_2 (MaxPoolin  (None, 6, 6, 512)         0         \n\n g2D)                                                            \n\n                                                                 \n\n dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n\n                                                                 \n\n conv2d_3 (Conv2D)           (None, 6, 6, 512)         2359808   \n\n                                                                 \n\n batch_normalization_3 (Bat  (None, 6, 6, 512)         2048      \n\n chNormalization)                                                \n\n                                                                 \n\n activation_3 (Activation)   (None, 6, 6, 512)         0         \n\n                                                                 \n\n max_pooling2d_3 (MaxPoolin  (None, 3, 3, 512)         0         \n\n g2D)                                                            \n\n                                                                 \n\n dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n\n                                                                 \n\n flatten (Flatten)           (None, 4608)              0         \n\n                                                                 \n\n dense (Dense)               (None, 256)               1179904   \n\n                                                                 \n\n batch_normalization_4 (Bat  (None, 256)               1024      \n\n chNormalization)                                                \n\n                                                                 \n\n activation_4 (Activation)   (None, 256)               0         \n\n                                                                 \n\n dropout_4 (Dropout)         (None, 256)               0         \n\n                                                                 \n\n dense_1 (Dense)             (None, 512)               131584    \n\n                                                                 \n\n batch_normalization_5 (Bat  (None, 512)               2048      \n\n chNormalization)                                                \n\n                                                                 \n\n activation_5 (Activation)   (None, 512)               0         \n\n                                                                 \n\n dropout_5 (Dropout)         (None, 512)               0         \n\n                                                                 \n\n dense_2 (Dense)             (None, 7)                 3591      \n\n                                                                 \n\n=================================================================\n\nTotal params: 4478727 (17.08 MB)\n\nTrainable params: 4474759 (17.07 MB)\n\nNon-trainable params: 3968 (15.50 KB)\n\n_________________________________________________________________\n"}]},{"cell_type":"markdown","source":"## Building the model","metadata":{}},{"cell_type":"code","source":"epochs = 15\nsteps_per_epoch = train_gen.n//train_gen.batch_size\nvalidation_steps = train_validation.n//train_validation.batch_size\ncheckpoint = ModelCheckpoint(\"model_weights.h5\",monitor='val_accuracy', save_weights_only=True, mode='max', verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1, patience=2, min_lr=0.00001)\ncallbacks = [checkpoint,reduce_lr]","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:27:50.814313Z","iopub.status.busy":"2024-02-26T12:27:50.813289Z","iopub.status.idle":"2024-02-26T12:27:50.819530Z","shell.execute_reply":"2024-02-26T12:27:50.818631Z","shell.execute_reply.started":"2024-02-26T12:27:50.814277Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Removed the whole training part for avoiding unnecessary long epochs list","metadata":{}},{"cell_type":"code","source":"history = model.fit(x= train_gen, steps_per_epoch= steps_per_epoch, epochs=epochs, validation_data=train_validation, validation_steps=validation_steps, callbacks=callbacks)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating the model","metadata":{}},{"cell_type":"code","source":"# Model evaluation\nmodel.evaluate(train_validation)","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:39:14.064393Z","iopub.status.busy":"2024-02-26T12:39:14.064044Z","iopub.status.idle":"2024-02-26T12:39:20.574751Z","shell.execute_reply":"2024-02-26T12:39:20.573875Z","shell.execute_reply.started":"2024-02-26T12:39:14.064368Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","output_type":"stream","text":"113/113 [==============================] - 6s 57ms/step - loss: 0.9863 - accuracy: 0.6325\n"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":["[0.9863303303718567, 0.6324881315231323]"]},"metadata":{}}]},{"cell_type":"markdown","source":"## saving the model architecture","metadata":{}},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model_a1.json\",\"w\") as json_file:\n    json_file.write(model_json)","metadata":{"execution":{"iopub.execute_input":"2024-02-26T12:40:53.289992Z","iopub.status.busy":"2024-02-26T12:40:53.289609Z","iopub.status.idle":"2024-02-26T12:40:53.309888Z","shell.execute_reply":"2024-02-26T12:40:53.308836Z","shell.execute_reply.started":"2024-02-26T12:40:53.289962Z"},"trusted":true},"execution_count":15,"outputs":[]}]}